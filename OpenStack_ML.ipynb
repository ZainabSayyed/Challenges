{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStack_WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import nltk.stem \n",
    "from nltk import stem\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomly select 1000 from bugslist and report (launch pad and stack over flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\buglist.xlsx\"\n",
    "df_launchpad=pd.read_excel(filename)\n",
    "filename = \"C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\report.xlsx\"\n",
    "df_stackoverflow = pd.read_excel(filename)\n",
    "stop_words=stopwords.words('english')\n",
    "stop_word_dict=[]\n",
    "for i in stop_words:\n",
    "    stop_word_dict.append(str(i.encode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes</th>\n",
       "      <th>fetch_url</th>\n",
       "      <th>title</th>\n",
       "      <th>longtext</th>\n",
       "      <th>answers</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://stackoverflow.com/search?sort=newest&amp;pa...</td>\n",
       "      <td>Q: Puppet Resource Ordering not working</td>\n",
       "      <td>I have a large manifest that sets up an OpenSt...</td>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/questions/40316293/pu...</td>\n",
       "      <td>2017-01-12 19:57:35</td>\n",
       "      <td>242af36b5b43854915c3de0453e113b0</td>\n",
       "      <td>[u'puppet', u'openstack', u'puppet-enterprise']</td>\n",
       "      <td>Cinder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/search?sort=newest&amp;pa...</td>\n",
       "      <td>Q: OpenStack With Manila Installation Fails fr...</td>\n",
       "      <td>Trying to install OpenStack Kilo version with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/questions/31160977/op...</td>\n",
       "      <td>2017-01-12 19:57:35</td>\n",
       "      <td>ecd5d0719e0acf92f31e21c87fbdde14</td>\n",
       "      <td>[u'installation', u'openstack', u'devstack']</td>\n",
       "      <td>Cinder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>http://stackoverflow.com/search?sort=newest&amp;pa...</td>\n",
       "      <td>A: jclouds with OpenStack =&gt; java.util.NoSuchE...</td>\n",
       "      <td>&gt; &lt;version&gt;${jclouds.version}&lt;/version&gt; &lt;/depe...</td>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/questions/21171261/jc...</td>\n",
       "      <td>2017-01-12 19:57:35</td>\n",
       "      <td>b955a0c030dcf83897d138c842af0072</td>\n",
       "      <td>[]</td>\n",
       "      <td>Cinder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>http://stackoverflow.com/search?sort=newest&amp;pa...</td>\n",
       "      <td>Q: Create an instance from volume in openstach...</td>\n",
       "      <td>I am trying to create an instance from a boota...</td>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/questions/27048292/cr...</td>\n",
       "      <td>2017-01-12 19:57:35</td>\n",
       "      <td>5430ad88204b92f03eb5bcbd0be11fa7</td>\n",
       "      <td>[u'python', u'openstack', u'novaclient', u'ope...</td>\n",
       "      <td>Cinder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/search?sort=newest&amp;pa...</td>\n",
       "      <td>Q: Devstack: There was an error submitting the...</td>\n",
       "      <td>instance from admin user(from demo user works ...</td>\n",
       "      <td>1</td>\n",
       "      <td>http://stackoverflow.com/questions/31105705/de...</td>\n",
       "      <td>2017-01-12 19:57:36</td>\n",
       "      <td>037c08accb1cf7dc4dab038195f59116</td>\n",
       "      <td>[u'ubuntu', u'cloud', u'openstack', u'devstack...</td>\n",
       "      <td>Cinder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  votes                                          fetch_url  \\\n",
       "0     0  http://stackoverflow.com/search?sort=newest&pa...   \n",
       "1     1  http://stackoverflow.com/search?sort=newest&pa...   \n",
       "2     0  http://stackoverflow.com/search?sort=newest&pa...   \n",
       "3     2  http://stackoverflow.com/search?sort=newest&pa...   \n",
       "4     1  http://stackoverflow.com/search?sort=newest&pa...   \n",
       "\n",
       "                                               title  \\\n",
       "0            Q: Puppet Resource Ordering not working   \n",
       "1  Q: OpenStack With Manila Installation Fails fr...   \n",
       "2  A: jclouds with OpenStack => java.util.NoSuchE...   \n",
       "3  Q: Create an instance from volume in openstach...   \n",
       "4  Q: Devstack: There was an error submitting the...   \n",
       "\n",
       "                                            longtext answers  \\\n",
       "0  I have a large manifest that sets up an OpenSt...       1   \n",
       "1  Trying to install OpenStack Kilo version with ...       1   \n",
       "2  > <version>${jclouds.version}</version> </depe...       1   \n",
       "3  I am trying to create an instance from a boota...       1   \n",
       "4  instance from admin user(from demo user works ...       1   \n",
       "\n",
       "                                                link                 date  \\\n",
       "0  http://stackoverflow.com/questions/40316293/pu...  2017-01-12 19:57:35   \n",
       "1  http://stackoverflow.com/questions/31160977/op...  2017-01-12 19:57:35   \n",
       "2  http://stackoverflow.com/questions/21171261/jc...  2017-01-12 19:57:35   \n",
       "3  http://stackoverflow.com/questions/27048292/cr...  2017-01-12 19:57:35   \n",
       "4  http://stackoverflow.com/questions/31105705/de...  2017-01-12 19:57:36   \n",
       "\n",
       "                                 id  \\\n",
       "0  242af36b5b43854915c3de0453e113b0   \n",
       "1  ecd5d0719e0acf92f31e21c87fbdde14   \n",
       "2  b955a0c030dcf83897d138c842af0072   \n",
       "3  5430ad88204b92f03eb5bcbd0be11fa7   \n",
       "4  037c08accb1cf7dc4dab038195f59116   \n",
       "\n",
       "                                                tags Unnamed: 9  \n",
       "0    [u'puppet', u'openstack', u'puppet-enterprise']     Cinder  \n",
       "1       [u'installation', u'openstack', u'devstack']     Cinder  \n",
       "2                                                 []     Cinder  \n",
       "3  [u'python', u'openstack', u'novaclient', u'ope...     Cinder  \n",
       "4  [u'ubuntu', u'cloud', u'openstack', u'devstack...     Cinder  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stackoverflow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_word_dict.append( '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'fault_description':random.sample(df_launchpad.fault_description,1000),'req':random.sample(df_launchpad.req,1000)},dtype=str)\n",
    "df_st=pd.DataFrame({'longtext':random.sample(df_stackoverflow.longtext,1000),'title':random.sample(df_stackoverflow.title,1000),'tags':random.sample(df_stackoverflow.tags,1000)},dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df=pd.DataFrame({'req':random.sample(df_launchpad.req,100),'bug':random.sample(df_launchpad.bug,100),'project':random.sample(df_launchpad.project,100),'fault_description':random.sample(df_launchpad.fault_description,100),'severity':random.sample(df_launchpad.severity,100),'submitter':random.sample(df_launchpad.submitter,100),'assignee':random.sample(df_launchpad.assignee,100),'created_date':random.sample(df_launchpad.created,100)})\n",
    "#df_st=pd.DataFrame({'fetch_url':random.sample(df_stackoverflow.fetch_url,100),'link':random.sample(df_stackoverflow.link,100),'date':random.sample(df_stackoverflow.date,100),'longtext':random.sample(df_stackoverflow.longtext,100),'title':random.sample(df_stackoverflow.title,100),'tags':random.sample(df_stackoverflow.tags,100),'id':random.sample(df_stackoverflow.id,100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df=pd.DataFrame({'req':df_launchpad.req,'bug':df_launchpad.bug,'project':df_launchpad.project,'fault_description':df_launchpad.fault_description,'severity':df_launchpad.severity,'submitter':df_launchpad.submitter,'assignee':df_launchpad.assignee,'created_date':df_launchpad.created})\n",
    "#df_st=pd.DataFrame({'fetch_url':df_stackoverflow.fetch_url,'link':df_stackoverflow.link,'date':df_stackoverflow.date,'longtext':df_stackoverflow.longtext,'title':df_stackoverflow.title,'tags':df_stackoverflow.tags,'id':df_stackoverflow['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fault_Details_lp= df.fault_description + df.req\n",
    "Fault_Details_st=pd.DataFrame(df_st.title + df_st.tags  + df_st.longtext.to_string())\n",
    "df=df.assign(Fault_Details_lp=Fault_Details_lp.values)\n",
    "df_st=df_st.assign(Fault_Details_st=Fault_Details_st.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove non-ascii character to process data using NLTK\n",
    "#NLTK coverts string into meaningful words called token, removes punctuations and special characters.\n",
    "#Analyzing Fault_desc and Req field from data set\n",
    "#write process data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dict(dataframe,field,stop_word_dict):\n",
    "    corpus=[]\n",
    "    for i in field:\n",
    "        for k in i:\n",
    "            if isinstance(k, str):\n",
    "                k = unicode(k, \"utf-8\") \n",
    "        corpus.append(str(i.encode(\"utf-8\")))         \n",
    "    dataframe['field_corpus']=pd.Series(corpus)\n",
    "    dataframe['field_corpus']=pd.Series( str(i).lower()  if len(str(i)) >0 else '' for i in dataframe.field_corpus)\n",
    "    corpus=[]\n",
    "    for i in dataframe.field_corpus:\n",
    "        data=(str(i))\n",
    "        data=re.sub(r'[^\\x00-\\x7f]','',data) or re.sub(r'[0-9]','',data)\n",
    "        corpus.append(data) \n",
    "    dataframe.field_corpus=pd.Series(corpus)\n",
    "    corpus=[]\n",
    "    for i in dataframe.field_corpus:\n",
    "        substr=re.split('[^A-Za-z]',i)\n",
    "        for j in substr:\n",
    "            j=j.strip()\n",
    "            if j not in stop_word_dict and len(j)>1:\n",
    "                corpus.append(j) \n",
    "        dataframe['field_corpus_words']=pd.Series(corpus)\n",
    "    field_words_count={}\n",
    "    print dataframe['field_corpus_words']\n",
    "    for w in corpus:\n",
    "        field_words_count[w]=field_words_count.get(w,0)+1 \n",
    "    return field_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fault_words_count={}\n",
    "fault_words_count=create_dict(df,df.fault_description,stop_word_dict)\n",
    "req_words_count={}\n",
    "req_words_count=create_dict(df,df.req,stop_word_dict)\n",
    "title_words_count={}\n",
    "title_words_count=create_dict(df_st,df_st.title,stop_word_dict)\n",
    "tags_words_count={}\n",
    "tags_words_count=create_dict(df_st,df_st.tags,stop_word_dict)\n",
    "longtext_words_count={}\n",
    "longtext_words_count=create_dict(df_st,df_st.longtext,stop_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "fault_words_count={}\n",
    "fault_words_list=[]\n",
    "fault_words_count,fault_words_list=create_dict(df,df.fault_description,stop_word_dict)\n",
    "\n",
    "req_words_count={}\n",
    "req_words_list=[]\n",
    "req_words_count,req_words_list=create_dict(df,df.req,stop_word_dict)\n",
    "    \n",
    "title_words_count={}\n",
    "title_words_list=[]\n",
    "title_words_count,title_words_list=create_dict(df_st,df_st.title,stop_word_dict)\n",
    "\n",
    "tags_words_count={}\n",
    "tags_words_list=[]\n",
    "tags_words_count,tags_words_list=create_dict(df_st,df_st.tags,stop_word_dict)\n",
    "\n",
    "list=[]\n",
    "for i in df_st.longtext:\n",
    "    list.append(i)\n",
    "\n",
    "corpus=[]\n",
    "for i in list:\n",
    "    for k in i:\n",
    "        if isinstance(k, str):\n",
    "            k = unicode(k, \"utf-8\") \n",
    "    corpus.append(str(i))         \n",
    "df_st['longtext_corpus']=pd.Series(corpus)\n",
    "df_st['longtext_corpus']=pd.Series( str(i).lower()  if len(str(i)) >0 else '' for i in df_st.longtext_corpus)\n",
    "\n",
    "corpus=[]\n",
    "for i in df_st.longtext_corpus:\n",
    "    data=(str(i))\n",
    "    data=re.sub(r'[^\\x00-\\x7f]','',data) or re.sub(r'[0-9]','',data)\n",
    "    corpus.append(data) \n",
    "df_st.longtext_corpus=pd.Series(corpus)\n",
    "corpus=[]\n",
    "for i in df_st.longtext_corpus:\n",
    "    substr=re.split('[^A-Za-z]',i)\n",
    "    for j in substr:\n",
    "        j=j.strip()\n",
    "        if j not in stop_word_dict and len(j)>1:\n",
    "            corpus.append(j) \n",
    "longtext_words_count={}\n",
    "longtext_words_list=[]\n",
    "for w in corpus:\n",
    "    longtext_words_count[w]=longtext_words_count.get(w,0)+1\n",
    "longtext_words_list=corpus'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creat dictionary for FaultDesc_Corpus and Req_Corpus\n",
    "df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sorted dictionary for FaultDesc_Corpus and Req_Corpus\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for key, value in sorted(fault_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "for key, value in sorted(req_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "for key, value in sorted(longtext_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "for key, value in sorted(title_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "for key, value in sorted(tags_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    mylist.append([key,value])\n",
    "df_wordcount=pd.DataFrame(mylist, columns =['Key','Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wordcount.to_csv('C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\dictionary_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"dictionary created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using TF-IDF to convert unstructured text to useful features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <a href=\"http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html\" target=\"_blank\" title=\"nlp.stanford.edu\" style=\"display: block; text-align: center;\"><img src=\"http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html\" alt=\"nlp.stanford.edu\" style=\"max-width: 100%;width: 800px;\"  width=\"800\"/></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'limited',\n",
       " 'pacemaker',\n",
       " 'prefix',\n",
       " 'crete',\n",
       " 'increase',\n",
       " 'patches',\n",
       " 'sorry',\n",
       " 'spec',\n",
       " 'vxlan',\n",
       " 'updated',\n",
       " 'every',\n",
       " 'updates',\n",
       " 'upstream',\n",
       " 'fuelclient',\n",
       " 'cause',\n",
       " 'upd',\n",
       " 'cmd',\n",
       " 'upload',\n",
       " 'rabbitmq',\n",
       " 'correct',\n",
       " 'convenience',\n",
       " 'notifying',\n",
       " 'cmp',\n",
       " 'force',\n",
       " 'incremented',\n",
       " 'consistent',\n",
       " 'direct',\n",
       " 'likely',\n",
       " 'consistencygroup',\n",
       " 'specs',\n",
       " 'even',\n",
       " 'errors',\n",
       " 'hide',\n",
       " 'selected',\n",
       " 'liberty',\n",
       " 'new',\n",
       " 'net',\n",
       " 'metadata',\n",
       " 'never',\n",
       " 'met',\n",
       " 'chassis',\n",
       " 'codecs',\n",
       " 'active',\n",
       " 'path',\n",
       " 'wdc',\n",
       " 'changed',\n",
       " 'reports',\n",
       " 'ignoring',\n",
       " 'orm',\n",
       " 'indentation',\n",
       " 'suitable',\n",
       " 'changes',\n",
       " 'astute',\n",
       " 'txn',\n",
       " 'prints',\n",
       " 'qcow',\n",
       " 'replace',\n",
       " 'org',\n",
       " 'glance',\n",
       " 'txt',\n",
       " 'unit',\n",
       " 'would',\n",
       " 'paramater',\n",
       " 'commandfailure',\n",
       " 'exited',\n",
       " 'call',\n",
       " 'therefore',\n",
       " 'dns',\n",
       " 'reproducibility',\n",
       " 'packetary',\n",
       " 'type',\n",
       " 'tell',\n",
       " 'vpp',\n",
       " 'successful',\n",
       " 'mznnldci',\n",
       " 'warn',\n",
       " 'defautl',\n",
       " 'aligned',\n",
       " 'eeae',\n",
       " 'describedby',\n",
       " 'must',\n",
       " 'join',\n",
       " 'err',\n",
       " 'mb',\n",
       " 'setup',\n",
       " 'work',\n",
       " 'doctype',\n",
       " 'worth',\n",
       " 'mu',\n",
       " 'mv',\n",
       " 'modify',\n",
       " 'install',\n",
       " 'exceptions',\n",
       " 'root',\n",
       " 'grenade',\n",
       " 'conf',\n",
       " 'repos',\n",
       " 'validates',\n",
       " 'reviewing',\n",
       " 'want',\n",
       " 'validated',\n",
       " 'end',\n",
       " 'turn',\n",
       " 'verify',\n",
       " 'urlsafe',\n",
       " 'vagrant',\n",
       " 'feature',\n",
       " 'machine',\n",
       " 'env',\n",
       " 'gate',\n",
       " 'config',\n",
       " 'ovs',\n",
       " 'sarfaty',\n",
       " 'description',\n",
       " 'insecure',\n",
       " 'openvswitch',\n",
       " 'wrong',\n",
       " 'ovn',\n",
       " 'parallel',\n",
       " 'types',\n",
       " 'third',\n",
       " 'bootstrap',\n",
       " 'alias',\n",
       " 'enter',\n",
       " 'button',\n",
       " 'operate',\n",
       " 'order',\n",
       " 'operations',\n",
       " 'executed',\n",
       " 'feedback',\n",
       " 'welcomed',\n",
       " 'functools',\n",
       " 'vary',\n",
       " 'concurrency',\n",
       " 'publicurl',\n",
       " 'cli',\n",
       " 'somewhere',\n",
       " 'fix',\n",
       " 'better',\n",
       " 'production',\n",
       " 'vmdk',\n",
       " 'kwargs',\n",
       " 'pass',\n",
       " 'cls',\n",
       " 'break',\n",
       " 'workflows',\n",
       " 'devstack',\n",
       " 'reasonably',\n",
       " 'timeout',\n",
       " 'debug',\n",
       " 'went',\n",
       " 'side',\n",
       " 'logs',\n",
       " 'solution',\n",
       " 'mirantis',\n",
       " 'message',\n",
       " 'overwrite',\n",
       " 'neutronmodule',\n",
       " 'bootstap',\n",
       " 'rw',\n",
       " 'network',\n",
       " 'restricted',\n",
       " 'rx',\n",
       " 'smp',\n",
       " 'content',\n",
       " 'dsl',\n",
       " 'rb',\n",
       " 'reader',\n",
       " 'got',\n",
       " 'resume',\n",
       " 'ntp',\n",
       " 'free',\n",
       " 'ncpu',\n",
       " 'externalmodel',\n",
       " 'carried',\n",
       " 'cinderclient',\n",
       " 'created',\n",
       " 'starts',\n",
       " 'traceback',\n",
       " 'messages',\n",
       " 'days',\n",
       " 'iso',\n",
       " 'resetting',\n",
       " 'features',\n",
       " 'executions',\n",
       " 'another',\n",
       " 'payload',\n",
       " 'tox',\n",
       " 'service',\n",
       " 'top',\n",
       " 'plentiful',\n",
       " 'needed',\n",
       " 'master',\n",
       " 'listed',\n",
       " 'geneve',\n",
       " 'alonso',\n",
       " 'tool',\n",
       " 'took',\n",
       " 'tokens',\n",
       " 'honolulu',\n",
       " 'symptom',\n",
       " 'nzq',\n",
       " 'suceeds',\n",
       " 'roles',\n",
       " 'older',\n",
       " 'enabled',\n",
       " 'second',\n",
       " 'project',\n",
       " 'enables',\n",
       " 'recheck',\n",
       " 'bridge',\n",
       " 'runner',\n",
       " 'navigate',\n",
       " 'ram',\n",
       " 'raw',\n",
       " 'icjjb',\n",
       " 'seen',\n",
       " 'seem',\n",
       " 'seek',\n",
       " 'mostly',\n",
       " 'convenient',\n",
       " 'isolated',\n",
       " 'unstack',\n",
       " 'invalidrequirement',\n",
       " 'though',\n",
       " 'object',\n",
       " 'metrics',\n",
       " 'scripts',\n",
       " 'doc',\n",
       " 'partition',\n",
       " 'flow',\n",
       " 'points',\n",
       " 'enterprise',\n",
       " 'dos',\n",
       " 'mailing',\n",
       " 'purged',\n",
       " 'datas',\n",
       " 'changeset',\n",
       " 'whitelist',\n",
       " 'probe',\n",
       " 'syntax',\n",
       " 'attempts',\n",
       " 'pkg',\n",
       " 'implementation',\n",
       " 'ldap',\n",
       " 'folder',\n",
       " 'dl',\n",
       " 'dm',\n",
       " 'df',\n",
       " 'dd',\n",
       " 'de',\n",
       " 'db',\n",
       " 'dc',\n",
       " 'preferred',\n",
       " 'da',\n",
       " 'report',\n",
       " 'ietf',\n",
       " 'fields',\n",
       " 'method',\n",
       " 'twice',\n",
       " 'zabbix',\n",
       " 'bac',\n",
       " 'release',\n",
       " 'respond',\n",
       " 'testing',\n",
       " 'observed',\n",
       " 'result',\n",
       " 'fail',\n",
       " 'subject',\n",
       " 'said',\n",
       " 'capacity',\n",
       " 'saio',\n",
       " 'urllib',\n",
       " 'symmetric',\n",
       " 'unable',\n",
       " 'propagated',\n",
       " 'discovery',\n",
       " 'debf',\n",
       " 'however',\n",
       " 'ws',\n",
       " 'packages',\n",
       " 'merging',\n",
       " 'urls',\n",
       " 'requests',\n",
       " 'com',\n",
       " 'ctxt',\n",
       " 'negotiation',\n",
       " 'represented',\n",
       " 'ntuple',\n",
       " 'diff',\n",
       " 'proceeded',\n",
       " 'fri',\n",
       " 'sharshov',\n",
       " 'much',\n",
       " 'expected',\n",
       " 'entered',\n",
       " 'website',\n",
       " 'xxx',\n",
       " 'jeos',\n",
       " 'child',\n",
       " 'catch',\n",
       " 'worked',\n",
       " 'exception',\n",
       " 'gnu',\n",
       " 'dashboard',\n",
       " 'setuptools',\n",
       " 'endpoints',\n",
       " 'spawn',\n",
       " 'ip',\n",
       " 'skipping',\n",
       " 'kuryr',\n",
       " 'io',\n",
       " 'ic',\n",
       " 'ib',\n",
       " 'ie',\n",
       " 'id',\n",
       " 'conn',\n",
       " 'containing',\n",
       " 'perform',\n",
       " 'things',\n",
       " 'make',\n",
       " 'fatal',\n",
       " 'potentially',\n",
       " 'several',\n",
       " 'couple',\n",
       " 'templates',\n",
       " 'installerror',\n",
       " 'hang',\n",
       " 'norwegian',\n",
       " 'openresolverproject',\n",
       " 'characters',\n",
       " 'insisted',\n",
       " 'thu',\n",
       " 'options',\n",
       " 'bugzilla',\n",
       " 'client',\n",
       " 'decrise',\n",
       " 'left',\n",
       " 'protocol',\n",
       " 'quoted',\n",
       " 'appropriately',\n",
       " 'ipaddr',\n",
       " 'newton',\n",
       " 'rotated',\n",
       " 'bandwidth',\n",
       " 'completed',\n",
       " 'thanks',\n",
       " 'human',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'previous',\n",
       " 'bnx',\n",
       " 'character',\n",
       " 'collections',\n",
       " 'easy',\n",
       " 'importlib',\n",
       " 'designate',\n",
       " 'opt',\n",
       " 'insensitive',\n",
       " 'breaks',\n",
       " 'possible',\n",
       " 'boxes',\n",
       " 'destroy',\n",
       " 'unique',\n",
       " 'daemon',\n",
       " 'grizzly',\n",
       " 'performing',\n",
       " 'manual',\n",
       " 'unnecessary',\n",
       " 'specific',\n",
       " 'private',\n",
       " 'steps',\n",
       " 'security',\n",
       " 'www',\n",
       " 'right',\n",
       " 'old',\n",
       " 'centos',\n",
       " 'people',\n",
       " 'sends',\n",
       " 'successfully',\n",
       " 'packagers',\n",
       " 'dear',\n",
       " 'library',\n",
       " 'confusing',\n",
       " 'total',\n",
       " 'tracked',\n",
       " 'normal',\n",
       " 'ice',\n",
       " 'environmentmodel',\n",
       " 'foo',\n",
       " 'localhost',\n",
       " 'core',\n",
       " 'repository',\n",
       " 'deleted',\n",
       " 'pose',\n",
       " 'keepalived',\n",
       " 'post',\n",
       " 'cdevice',\n",
       " 'obj',\n",
       " 'attacks',\n",
       " 'neuntron',\n",
       " 'ligfjdgl',\n",
       " 'misleading',\n",
       " 'ensure',\n",
       " 'horizon',\n",
       " 'commit',\n",
       " 'slightly',\n",
       " 'obs',\n",
       " 'automatically',\n",
       " 'soa',\n",
       " 'raised',\n",
       " 'destination',\n",
       " 'publishing',\n",
       " 'dashboards',\n",
       " 'lies',\n",
       " 'rely',\n",
       " 'git',\n",
       " 'support',\n",
       " 'nova',\n",
       " 'class',\n",
       " 'gig',\n",
       " 'stuck',\n",
       " 'way',\n",
       " 'head',\n",
       " 'sqlalchemy',\n",
       " 'typo',\n",
       " 'differences',\n",
       " 'removes',\n",
       " 'puppetsync',\n",
       " 'failure',\n",
       " 'heat',\n",
       " 'encoded',\n",
       " 'removed',\n",
       " 'true',\n",
       " 'fuelmain',\n",
       " 'versions',\n",
       " 'rootwrap',\n",
       " 'inside',\n",
       " 'attached',\n",
       " 'mtu',\n",
       " 'considered',\n",
       " 'stackforge',\n",
       " 'fuellib',\n",
       " 'ddos',\n",
       " 'exist',\n",
       " 'phyad',\n",
       " 'floating',\n",
       " 'check',\n",
       " 'physical',\n",
       " 'blatantly',\n",
       " 'nb',\n",
       " 'ne',\n",
       " 'setting',\n",
       " 'role',\n",
       " 'irclogs',\n",
       " 'test',\n",
       " 'jenkins',\n",
       " 'ns',\n",
       " 'node',\n",
       " 'models',\n",
       " 'kvm',\n",
       " 'update',\n",
       " 'scale',\n",
       " 'sql',\n",
       " 'variable',\n",
       " 'configs',\n",
       " 'died',\n",
       " 'hashing',\n",
       " 'longer',\n",
       " 'interval',\n",
       " 'modules',\n",
       " 'time',\n",
       " 'stacks',\n",
       " 'mydomain',\n",
       " 'kzsi',\n",
       " 'broke',\n",
       " 'skip',\n",
       " 'redeployment',\n",
       " 'global',\n",
       " 'ost',\n",
       " 'excutils',\n",
       " 'manager',\n",
       " 'displaying',\n",
       " 'osd',\n",
       " 'row',\n",
       " 'ver',\n",
       " 'zone',\n",
       " 'graph',\n",
       " 'gigs',\n",
       " 'environment',\n",
       " 'dbcf',\n",
       " 'circumstances',\n",
       " 'scroiset',\n",
       " 'downloading',\n",
       " 'qgymvjb',\n",
       " 'string',\n",
       " 'partitions',\n",
       " 'committers',\n",
       " 'level',\n",
       " 'registered',\n",
       " 'iter',\n",
       " 'leave',\n",
       " 'solved',\n",
       " 'defaults',\n",
       " 'team',\n",
       " 'dir',\n",
       " 'prevent',\n",
       " 'unexpected',\n",
       " 'repetitive',\n",
       " 'erquery',\n",
       " 'initialized',\n",
       " 'port',\n",
       " 'dsvm',\n",
       " 'current',\n",
       " 'suspect',\n",
       " 'template',\n",
       " 'shared',\n",
       " 'satisfy',\n",
       " 'kilowiththecustomeractive',\n",
       " 'camel',\n",
       " 'downloaded',\n",
       " 'groups',\n",
       " 'address',\n",
       " 'apache',\n",
       " 'change',\n",
       " 'wait',\n",
       " 'incoming',\n",
       " 'commonly',\n",
       " 'example',\n",
       " 'queue',\n",
       " 'dtantsur',\n",
       " 'horban',\n",
       " 'navigation',\n",
       " 'heatclient',\n",
       " 'tasks',\n",
       " 'os',\n",
       " 'ls',\n",
       " 'marked',\n",
       " 'ipv',\n",
       " 'fake',\n",
       " 'perf',\n",
       " 'working',\n",
       " 'live',\n",
       " 'handler',\n",
       " 'https',\n",
       " 'memory',\n",
       " 'msg',\n",
       " 'scope',\n",
       " 'fallocate',\n",
       " 'cfcb',\n",
       " 'netinst',\n",
       " 'cases',\n",
       " 'easiest',\n",
       " 'defeats',\n",
       " 'originally',\n",
       " 'reviews',\n",
       " 'rados',\n",
       " 'printing',\n",
       " 'values',\n",
       " 'following',\n",
       " 'making',\n",
       " 'cae',\n",
       " 'attribute',\n",
       " 'agent',\n",
       " 'paused',\n",
       " 'logrotate',\n",
       " 'listens',\n",
       " 'requirements',\n",
       " 'fpb',\n",
       " 'oslo',\n",
       " 'discussion',\n",
       " 'charset',\n",
       " 'rpcutil',\n",
       " 'orginal',\n",
       " 'parameter',\n",
       " 'map',\n",
       " 'product',\n",
       " 'huge',\n",
       " 'may',\n",
       " 'max',\n",
       " 'respective',\n",
       " 'sni',\n",
       " 'mac',\n",
       " 'produce',\n",
       " 'date',\n",
       " 'data',\n",
       " 'recursive',\n",
       " 'stdin',\n",
       " 'explicit',\n",
       " 'su',\n",
       " 'st',\n",
       " 'switch',\n",
       " 'sh',\n",
       " 'representation',\n",
       " 'repair',\n",
       " 'pointed',\n",
       " 'displayed',\n",
       " 'unacceptable',\n",
       " 'damage',\n",
       " 'dcac',\n",
       " 'cold',\n",
       " 'still',\n",
       " 'nsm',\n",
       " 'tore',\n",
       " 'group',\n",
       " 'monitor',\n",
       " 'swann',\n",
       " 'duplex',\n",
       " 'sdague',\n",
       " 'forms',\n",
       " 'yaml',\n",
       " 'warpc',\n",
       " 'main',\n",
       " 'texas',\n",
       " 'non',\n",
       " 'rake',\n",
       " 'half',\n",
       " 'complement',\n",
       " 'nov',\n",
       " 'secgroup',\n",
       " 'permissions',\n",
       " 'execute',\n",
       " 'name',\n",
       " 'drop',\n",
       " 'revert',\n",
       " 'possibilities',\n",
       " 'nouniquematch',\n",
       " 'attributeerror',\n",
       " 'el',\n",
       " 'domain',\n",
       " 'en',\n",
       " 'ee',\n",
       " 'ed',\n",
       " 'ef',\n",
       " 'ea',\n",
       " 'snapshots',\n",
       " 'eb',\n",
       " 'gioiaibwvzc',\n",
       " 'naming',\n",
       " 'er',\n",
       " 'subnet',\n",
       " 'restfulclient',\n",
       " 'container',\n",
       " 'space',\n",
       " 'nameservers',\n",
       " 'interference',\n",
       " 'looking',\n",
       " 'aeb',\n",
       " 'internet',\n",
       " 'suggesting',\n",
       " 'bugging',\n",
       " 'manuals',\n",
       " 'shows',\n",
       " 'tmpl',\n",
       " 'dockerredis',\n",
       " 'args',\n",
       " 'mechanisms',\n",
       " 'possibility',\n",
       " 'diagnostic',\n",
       " 'dependencies',\n",
       " 'lma',\n",
       " 'dispatcher',\n",
       " 'recon',\n",
       " 'tries',\n",
       " 'thing',\n",
       " 'fc',\n",
       " 'place',\n",
       " 'router',\n",
       " 'think',\n",
       " 'first',\n",
       " 'midonet',\n",
       " 'saving',\n",
       " 'redhat',\n",
       " 'omitted',\n",
       " 'variables',\n",
       " 'one',\n",
       " 'fast',\n",
       " 'directly',\n",
       " 'impossible',\n",
       " 'array',\n",
       " 'open',\n",
       " 'size',\n",
       " 'given',\n",
       " 'checked',\n",
       " 'workaround',\n",
       " 'caught',\n",
       " 'broadcom',\n",
       " 'returns',\n",
       " 'params',\n",
       " 'unreachable',\n",
       " 'configured',\n",
       " 'uniqueconstraint',\n",
       " 'releases',\n",
       " 'broadcast',\n",
       " 'github',\n",
       " 'copy',\n",
       " 'specify',\n",
       " 'population',\n",
       " 'require',\n",
       " 'future',\n",
       " 'booted',\n",
       " 'pre',\n",
       " 'files',\n",
       " 'netaddr',\n",
       " 'san',\n",
       " 'remained',\n",
       " 'argument',\n",
       " 'saw',\n",
       " 'conversion',\n",
       " 'upgrading',\n",
       " 'aside',\n",
       " 'note',\n",
       " 'take',\n",
       " 'online',\n",
       " 'performance',\n",
       " 'switching',\n",
       " 'begin',\n",
       " 'sure',\n",
       " 'offload',\n",
       " 'trace',\n",
       " 'replicas',\n",
       " 'buffer',\n",
       " 'fca',\n",
       " 'fcb',\n",
       " 'inserted',\n",
       " 'groupntpsync',\n",
       " 'later',\n",
       " 'slaves',\n",
       " 'qos',\n",
       " 'show',\n",
       " 'discovered',\n",
       " 'xml',\n",
       " 'fibre',\n",
       " 'upgrade',\n",
       " 'title',\n",
       " 'outside',\n",
       " 'deployments',\n",
       " 'dict',\n",
       " 'ethtool',\n",
       " 'startswith',\n",
       " 'closed',\n",
       " 'get',\n",
       " 'stomp',\n",
       " 'repo',\n",
       " 'ssl',\n",
       " 'qdhcp',\n",
       " 'pipermail',\n",
       " 'gen',\n",
       " 'gem',\n",
       " 'resource',\n",
       " 'settings',\n",
       " 'yield',\n",
       " 'prevents',\n",
       " 'bdadfaf',\n",
       " 'middleware',\n",
       " 'wiki',\n",
       " 'kernel',\n",
       " 'kibana',\n",
       " 'kmod',\n",
       " 'fails',\n",
       " 'invoked',\n",
       " 'ways',\n",
       " 'subsequent',\n",
       " 'review',\n",
       " 'getattr',\n",
       " 'osnailyfacter',\n",
       " 'bbefd',\n",
       " 'import',\n",
       " 'reading',\n",
       " 'checks',\n",
       " 'notice',\n",
       " 'infrastructure',\n",
       " 'jobs',\n",
       " 'parent',\n",
       " 'screen',\n",
       " 'lockutils',\n",
       " 'tue',\n",
       " 'uuid',\n",
       " 'installation',\n",
       " 'configuring',\n",
       " 'dragonflow',\n",
       " 'many',\n",
       " 'region',\n",
       " 'according',\n",
       " 'contract',\n",
       " 'orchestration',\n",
       " 'delete',\n",
       " 'filtering',\n",
       " 'bfde',\n",
       " 'dispatch',\n",
       " 'vtp',\n",
       " 'late',\n",
       " 'tuning',\n",
       " 'subjectaltname',\n",
       " 'idasicj',\n",
       " 'locally',\n",
       " 'valueerror',\n",
       " 'engine',\n",
       " 'bmc',\n",
       " 'enable',\n",
       " 'bootsraped',\n",
       " 'hits',\n",
       " 'wake',\n",
       " 'external',\n",
       " 'ruby',\n",
       " 'former',\n",
       " 'case',\n",
       " 'cadca',\n",
       " 'compile',\n",
       " 'cast',\n",
       " 'mysels',\n",
       " 'situation',\n",
       " 'mos',\n",
       " 'stdout',\n",
       " 'metric',\n",
       " 'sleeping',\n",
       " 'parse',\n",
       " 'cluster',\n",
       " 'ced',\n",
       " 'converts',\n",
       " 'ironic',\n",
       " 'different',\n",
       " 'author',\n",
       " 'media',\n",
       " 'hostname',\n",
       " 'epmd',\n",
       " 'html',\n",
       " 'interfacetobridgecommand',\n",
       " 'arguments',\n",
       " 'subunit',\n",
       " 'httpsclient',\n",
       " 'status',\n",
       " 'visually',\n",
       " 'croiset',\n",
       " 'driver',\n",
       " 'drives',\n",
       " 'transceiver',\n",
       " 'running',\n",
       " 'bouatxg',\n",
       " 'changing',\n",
       " 'validate',\n",
       " 'implements',\n",
       " 'supports',\n",
       " 'undefined',\n",
       " 'intermittent',\n",
       " 'parameterised',\n",
       " 'ccp',\n",
       " 'without',\n",
       " 'components',\n",
       " 'termination',\n",
       " 'model',\n",
       " 'ccb',\n",
       " 'resp',\n",
       " 'rest',\n",
       " 'kill',\n",
       " 'kilo',\n",
       " 'touch',\n",
       " 'speed',\n",
       " 'captured',\n",
       " 'seems',\n",
       " 'except',\n",
       " 'param',\n",
       " 'blob',\n",
       " 'mesagess',\n",
       " 'vudcisicjzdgftcci',\n",
       " 'ami',\n",
       " 'uploadfile',\n",
       " 'rules',\n",
       " 'traffic',\n",
       " 'mon',\n",
       " 'listening',\n",
       " 'using',\n",
       " 'execution',\n",
       " 'developers',\n",
       " 'intel',\n",
       " 'reduces',\n",
       " 'server',\n",
       " 'sanity',\n",
       " 'dnsmasq',\n",
       " 'either',\n",
       " 'output',\n",
       " 'queues',\n",
       " 'grub',\n",
       " 'exposed',\n",
       " 'modindex',\n",
       " 'erase',\n",
       " 'images',\n",
       " 'allocated',\n",
       " 'generates',\n",
       " 'provided',\n",
       " 'vzl',\n",
       " 'recorded',\n",
       " 'grafana',\n",
       " 'exit',\n",
       " 'provider',\n",
       " 'refer',\n",
       " 'vg',\n",
       " 'reasonable',\n",
       " 'power',\n",
       " 'seconds',\n",
       " 'broken',\n",
       " 'standpoint',\n",
       " 'timesync',\n",
       " 'throw',\n",
       " 'resolvers',\n",
       " 'src',\n",
       " 'package',\n",
       " 'classifier',\n",
       " 'wefollowedthissteps',\n",
       " 'srv',\n",
       " 'greatly',\n",
       " 'backup',\n",
       " 'processor',\n",
       " 'referenced',\n",
       " 'image',\n",
       " 'references',\n",
       " 'determine',\n",
       " 'parties',\n",
       " 'loc',\n",
       " 'log',\n",
       " 'prepare',\n",
       " 'testvm',\n",
       " 'decode',\n",
       " 'start',\n",
       " 'lot',\n",
       " 'norcert',\n",
       " 'kolla',\n",
       " 'dbfb',\n",
       " 'complete',\n",
       " 'enough',\n",
       " 'jun',\n",
       " 'jul',\n",
       " 'trying',\n",
       " 'hostinfo',\n",
       " 'default',\n",
       " 'expect',\n",
       " 'detailed',\n",
       " 'hernandez',\n",
       " 'ac',\n",
       " 'ab',\n",
       " 'ae',\n",
       " 'ad',\n",
       " 'cbe',\n",
       " 'migrate',\n",
       " 'certain',\n",
       " 'describe',\n",
       " 'moved',\n",
       " 'general',\n",
       " 'file',\n",
       " 'identifiersshould',\n",
       " 'lifetime',\n",
       " 'incorrect',\n",
       " 'drivers',\n",
       " 'storage',\n",
       " 'gettext',\n",
       " 'field',\n",
       " 'terminating',\n",
       " 'forcing',\n",
       " 'requested',\n",
       " 'separate',\n",
       " 'includes',\n",
       " 'physnets',\n",
       " 'important',\n",
       " 'registry',\n",
       " 'pool',\n",
       " 'whitespace',\n",
       " 'building',\n",
       " 'remote',\n",
       " 'calls',\n",
       " 'finished',\n",
       " 'chown',\n",
       " 'directory',\n",
       " 'starting',\n",
       " 'dist',\n",
       " 'caused',\n",
       " 'alerting',\n",
       " 'executing',\n",
       " 'migrates',\n",
       " 'follow',\n",
       " 'disk',\n",
       " 'scp',\n",
       " 'causes',\n",
       " 'tx',\n",
       " 'tt',\n",
       " 'encourage',\n",
       " 'prefixes',\n",
       " 'tarball',\n",
       " 'init',\n",
       " 'nodes',\n",
       " 'tb',\n",
       " 'immutable',\n",
       " 'returned',\n",
       " 'returning',\n",
       " 'rc',\n",
       " 'gz',\n",
       " 'util',\n",
       " 'difference',\n",
       " 'glanceclient',\n",
       " 'list',\n",
       " 'large',\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict=set(df_wordcount.Key)\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "req_words_dict=dict.fromkeys(mydict,0)\n",
    "title_words_dict=dict.fromkeys(mydict,0)\n",
    "tags_words_dict=dict.fromkeys(mydict,0)\n",
    "longtext_words_dict=dict.fromkeys(mydict,0)\n",
    "fault_words_dict=dict.fromkeys(mydict,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aas</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abb</th>\n",
       "      <th>able</th>\n",
       "      <th>ac</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>ywwioiawfswgim</th>\n",
       "      <th>zabbix</th>\n",
       "      <th>zaqar</th>\n",
       "      <th>zdgfjay</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zsfciibbtkqgdgfnczpcimnvbnnvbgvcilxuiiwgimdyyxbobw</th>\n",
       "      <th>zxj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aas  ab  aba  abb  able  ac  acceptance  access  according ...   yet  \\\n",
       "0   0    0   0    0    0     0   0           0       0          0 ...     0   \n",
       "1   0    0   0    0    0     0   0           0       0          0 ...     0   \n",
       "2   0    0   0    0    0     0   0           0       0          0 ...     0   \n",
       "3   0    0   0    0    0     0   0           0       0          0 ...     0   \n",
       "4   0    0   0    0    0     0   0           0       0          0 ...     0   \n",
       "\n",
       "   yield  ywwioiawfswgim  zabbix  zaqar  zdgfjay  zero  zone  \\\n",
       "0      0               0       0      0        0     0     0   \n",
       "1      0               0       0      0        0     0     0   \n",
       "2      0               0       0      0        0     0     0   \n",
       "3      0               0       0      0        0     0     0   \n",
       "4      0               0       0      0        0     0     0   \n",
       "\n",
       "   zsfciibbtkqgdgfnczpcimnvbnnvbgvcilxuiiwgimdyyxbobw  zxj  \n",
       "0                                                  0     0  \n",
       "1                                                  0     0  \n",
       "2                                                  0     0  \n",
       "3                                                  0     0  \n",
       "4                                                  0     0  \n",
       "\n",
       "[5 rows x 1999 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading=['req_words', 'title_words','tags_words','longtext_words','fault_words']\n",
    "Matrix=pd.DataFrame([req_words_dict,title_words_dict,tags_words_dict,longtext_words_dict,fault_words_dict])\n",
    "Temp=pd.Series(heading)\n",
    "Matrix1=Matrix.copy()\n",
    "Matrix1= Matrix1.assign(Temp=Temp.values)\n",
    "Matrix1.index=Temp\n",
    "Temp1= pd.DataFrame.transpose( Matrix1)\n",
    "Temp1.to_csv('C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\matrix_sample.csv')\n",
    "Matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeTF(mydict, field):\n",
    "    tfDict = {}\n",
    "    fieldCount= len(field)\n",
    "    for key, value in mydict.iteritems():\n",
    "        tfDict[key] = value/ float(fieldCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title_words_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-56305078f287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_title_words_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_words_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf_tags_words_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags_words_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf_longtext_words_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongtext_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlongtext_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf_fault_words_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfault_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfault_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf_req_words_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreq_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'title_words_list' is not defined"
     ]
    }
   ],
   "source": [
    "tf_title_words_list = computeTF(title_words_dict, title_words_list)\n",
    "tf_tags_words_list = computeTF(tags_words_dict, tags_words_list)\n",
    "tf_longtext_words_list = computeTF(longtext_words_dict,longtext_words_list)\n",
    "tf_fault_words_list = computeTF(fault_words_dict,fault_words_list)\n",
    "tf_req_words_list = computeTF(req_words_dict,req_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict= {}\n",
    "    N= len(docList)\n",
    "    idfDict = dict.fromkeys(docList[0].keys(),0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.iteritems():\n",
    "            if val > 0:\n",
    "                idfDict[word]+=1\n",
    "    for word,val in idfDict.iteritems():\n",
    "        idfDict[word] = math.log(N/ float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2d6229c9d8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomputeIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreq_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtags_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlongtext_words_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfault_words_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-a6736dd911c4>\u001b[0m in \u001b[0;36mcomputeIDF\u001b[0;34m(docList)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0midfDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midfDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0midfDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0midfDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "idfs=computeIDF([req_words_dict,title_words_dict,tags_words_dict,longtext_words_dict,fault_words_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeTFIDF(tfList, idfs):\n",
    "    tfidf={}\n",
    "    for word,val in tfList.iteritems():\n",
    "        tfidf[word]= val *  idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_title_words_list = computeTFIDF(tf_title_words_list, idfs)\n",
    "tfidf_tags_words_list = computeTF(tf_tags_words_list, idfs)\n",
    "tfidf_longtext_words_list = computeTF(tf_longtext_words_list,idfs)\n",
    "tfidf_fault_words_list = computeTF(tf_fault_words_list,idfs)\n",
    "tfidf_req_words_list = computeTF(tf_req_words_list,idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heading=['req_words', 'title_words','tags_words','longtext_words','fault_words']\n",
    "tfMatrix=pd.DataFrame([tfidf_title_words_list,tfidf_tags_words_list,tfidf_longtext_words_list,tfidf_fault_words_list,tfidf_req_words_list])\n",
    "Temp=pd.Series(heading)\n",
    "tfMatrix= tfMatrix.assign(Temp=Temp.values)\n",
    "tfMatrix.index=Temp\n",
    "tfTemp1= pd.DataFrame.transpose(tfMatrix)\n",
    "tfTemp1.to_csv('C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\tfmatrix.csv')\n",
    "tfTemp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(df.Fault_Details_lp)\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "%time km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(km,  'C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\LaundPad.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = joblib.load('C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\LaundPad.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Cluster=pd.Series(clusters)\n",
    "df=df.assign(Cluster=Cluster.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\Users\\\\zaina\\\\Documents\\\\DataVisulaization_MachineLearning\\\\Open_Stack\\\\Classified_LaunchPad.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=mylist['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "bow1 = simple_vectorizer.fit_transform(df.Fault_Details_lp).todense()\n",
    "bow2 = simple_vectorizer.fit_transform(df_st.Fault_Details_lp).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print bow1,bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = list(simple_vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert bow to DataFrame\n",
    "bow1_df = pd.DataFrame(bow1, index=df.index, columns = words)\n",
    "bow2_df = pd.DataFrame(bow2, index=df_st.index, columns = words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_lp= df.join(bow1_df)\n",
    "train_data_st= df.join(bow2_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "summary": "ML_FaultGenes",
   "url": "https://anaconda.org/zainabsayyed/openstack_ml"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
